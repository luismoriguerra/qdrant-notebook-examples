{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-31 21:28:28--  https://storage.googleapis.com/tutorial-attachments/code-search/structures.jsonl\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.186.207, 142.251.0.207, 142.250.0.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.186.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4921256 (4.7M) [application/json]\n",
      "Saving to: ‘structures.jsonl.4’\n",
      "\n",
      "structures.jsonl.4  100%[===================>]   4.69M  4.54MB/s    in 1.0s    \n",
      "\n",
      "2025-01-31 21:28:30 (4.54 MB/s) - ‘structures.jsonl.4’ saved [4921256/4921256]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://storage.googleapis.com/tutorial-attachments/code-search/structures.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "structures = []\n",
    "with open(\"structures.jsonl\", \"r\") as fp:\n",
    "    for i, row in enumerate(fp):\n",
    "        entry = json.loads(row)\n",
    "        structures.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install inflection --quiet\n",
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inflection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install inflection --quiet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minflection\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inflection'"
     ]
    }
   ],
   "source": [
    "!pip install inflection --quiet\n",
    "\n",
    "import inflection\n",
    "import re\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "def textify(chunk: Dict[str, Any]) -> str:\n",
    "    # Get rid of all the camel case / snake case\n",
    "    # - inflection.underscore changes the camel case to snake case\n",
    "    # - inflection.humanize converts the snake case to human readable form\n",
    "    name = inflection.humanize(inflection.underscore(chunk[\"name\"]))\n",
    "    signature = inflection.humanize(inflection.underscore(chunk[\"signature\"]))\n",
    "\n",
    "    # Check if docstring is provided\n",
    "    docstring = \"\"\n",
    "    if chunk[\"docstring\"]:\n",
    "        docstring = f\"that does {chunk['docstring']} \"\n",
    "\n",
    "    # Extract the location of that snippet of code\n",
    "    context = (\n",
    "        f\"module {chunk['context']['module']} \"\n",
    "        f\"file {chunk['context']['file_name']}\"\n",
    "    )\n",
    "    if chunk[\"context\"][\"struct_name\"]:\n",
    "        struct_name = inflection.humanize(\n",
    "            inflection.underscore(chunk[\"context\"][\"struct_name\"])\n",
    "        )\n",
    "        context = f\"defined in struct {struct_name} {context}\"\n",
    "\n",
    "    # Combine all the bits and pieces together\n",
    "    text_representation = (\n",
    "        f\"{chunk['code_type']} {name} \"\n",
    "        f\"{docstring}\"\n",
    "        f\"defined as {signature} \"\n",
    "        f\"{context}\"\n",
    "    )\n",
    "\n",
    "    # Remove any special characters and concatenate the tokens\n",
    "    tokens = re.split(r\"\\W\", text_representation)\n",
    "    tokens = filter(lambda x: x, tokens)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_representations = list(map(textify, structures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers optimum onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nlp_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "nlp_embeddings = nlp_model.encode(\n",
    "    text_representations, show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"THIS_IS_YOUR_TOKEN\" ## hugging face token\n",
    "\n",
    "# Extract the code snippets from the structures to a separate list\n",
    "code_snippets = [\n",
    "    structure[\"context\"][\"snippet\"] for structure in structures\n",
    "]\n",
    "\n",
    "code_model = SentenceTransformer(\n",
    "    \"jinaai/jina-embeddings-v2-base-code\",\n",
    "    token=HF_TOKEN,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "code_model.max_seq_length = 8192  # increase the context length window\n",
    "code_embeddings = code_model.encode(\n",
    "    code_snippets, batch_size=4, show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "client.create_collection(\n",
    "    \"qdrant-sources\",\n",
    "    vectors_config={\n",
    "        \"text\": models.VectorParams(\n",
    "            size=nlp_embeddings.shape[1],\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "        \"code\": models.VectorParams(\n",
    "            size=code_embeddings.shape[1],\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "points = [\n",
    "    models.PointStruct(\n",
    "        id=uuid.uuid4().hex,\n",
    "        vector={\n",
    "            \"text\": text_embedding,\n",
    "            \"code\": code_embedding,\n",
    "        },\n",
    "        payload=structure,\n",
    "    )\n",
    "    for text_embedding, code_embedding, structure in zip(nlp_embeddings, code_embeddings, structures)\n",
    "]\n",
    "\n",
    "client.upload_points(\"qdrant-sources\", points=points, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I count points in a collection?\"\n",
    "\n",
    "hits = client.query_points(\n",
    "    \"qdrant-sources\",\n",
    "    query=nlp_model.encode(query).tolist(),\n",
    "    using=\"text\",\n",
    "    limit=5,\n",
    ").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = client.query_points(\n",
    "    \"qdrant-sources\",\n",
    "    query=code_model.encode(query).tolist(),\n",
    "    using=\"code\",\n",
    "    limit=5,\n",
    ").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = client.query_batch_points(\n",
    "    \"qdrant-sources\",\n",
    "    requests=[\n",
    "        models.QueryRequest(\n",
    "            query=nlp_model.encode(query).tolist(),\n",
    "            using=\"text\",\n",
    "            with_payload=True,\n",
    "            limit=5,\n",
    "        ),\n",
    "        models.QueryRequest(\n",
    "            query=code_model.encode(query).tolist(),\n",
    "            using=\"code\",\n",
    "            with_payload=True,\n",
    "            limit=5,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "results = [response.points for response in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.search_groups(\n",
    "    \"qdrant-sources\",\n",
    "    query_vector=(\n",
    "        \"code\", code_model.encode(query).tolist()\n",
    "    ),\n",
    "    group_by=\"context.module\",\n",
    "    limit=5,\n",
    "    group_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see example https://github.com/qdrant/demo-code-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
